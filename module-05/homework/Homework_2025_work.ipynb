{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiGr9mW0Z5sCllyPpYWy9k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tinker0425/de-zoomcamp-my-work/blob/master/Homework_2025_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Feu5NVvhqwjO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyspark\n",
        "!pip install findspark\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "ApyzXNHurDmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "        .appName('testColab') \\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "7IRaxKrirGGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually Stop at ngrok if another spark is running"
      ],
      "metadata": {
        "id": "lu6qfO_qszvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied \"\n",
        "\"from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "ui_port = 4040\n",
        "public_url = ngrok.connect(ui_port).public_url\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{ui_port}\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW6wl5LcrLaK",
        "outputId": "731b83ea-d53b-4b5d-aa36-f7ea50774698"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-03-04T01:09:10+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://9e14-34-80-91-86.ngrok-free.app\" -> \"http://127.0.0.1:4040\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "\n",
        "file_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-10.parquet'\n",
        "spark.sparkContext.addFile(file_url)\n",
        "\n",
        "# Read into Spark DF\n",
        "df = spark.read.parquet(SparkFiles.get('yellow_tripdata_2024-10.parquet'), header=True)\n",
        "\n",
        "df.count()"
      ],
      "metadata": {
        "id": "XPU7OBZgrdqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439374a8-3871-4c5e-c982-19e8e1979289"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3833771"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "\n",
        "Answer - 3.5.5"
      ],
      "metadata": {
        "id": "QhQMIcQcrqjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.version"
      ],
      "metadata": {
        "id": "_diGqY2arpL4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c4f6deb-ad97-441e-cc08-f41b59729380"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.5.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "\n",
        "Answer - 25MB\n",
        "\n",
        "https://www.youtube.com/watch?v=r_Sf6fCB40c&list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&index=47\n",
        "\n",
        "spark.createDataFrame(df_pandas).schema"
      ],
      "metadata": {
        "id": "SYXflbTbtRux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repartition the Dataframe to 4 partitions and save it to parquet.\n",
        "df = df.repartition(4)"
      ],
      "metadata": {
        "id": "rf0raGFctS_x"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.parquet('yellow_trip_4_par')"
      ],
      "metadata": {
        "id": "2_ft-BZ4xRRr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "parquet_dir = '/content/yellow_trip_4_par/'\n",
        "files = os.listdir(parquet_dir)\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fpS3hkwzgHl",
        "outputId": "b4ff98ee-eabe-4d2b-fef2-6a300dc1c7ff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.part-00001-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet.crc', 'part-00001-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet', 'part-00000-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet', 'part-00002-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet', '.part-00000-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet.crc', 'part-00003-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet', '.part-00002-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet.crc', '_SUCCESS', '.part-00003-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet.crc', '._SUCCESS.crc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only .parquet files\n",
        "parquet_files = [f for f in files if f.endswith('.parquet')]\n",
        "print(parquet_files)\n",
        "# Corrected version of the last line\n",
        "parquet_file_sizes = [(f, os.path.getsize(os.path.join(parquet_dir, f))) for f in parquet_files]\n",
        "\n",
        "# Optionally, convert to MB\n",
        "parquet_file_sizes_in_MB = [(f, size / (1024 * 1024)) for f, size in parquet_file_sizes]\n",
        "\n",
        "# Print the result\n",
        "for file, size in parquet_file_sizes_in_MB:\n",
        "    print(f\"File: {file}, Size: {size:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c3XWuQ-0D26",
        "outputId": "4595d7db-b79f-4167-c0ec-2ca3eb4b32d3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['part-00001-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet', 'part-00000-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet', 'part-00002-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet', 'part-00003-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet']\n",
            "File: part-00001-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet, Size: 23.02 MB\n",
            "File: part-00000-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet, Size: 23.04 MB\n",
            "File: part-00002-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet, Size: 23.06 MB\n",
            "File: part-00003-4b6f94a3-5b5a-40e9-b862-14d9d65cd157-c000.snappy.parquet, Size: 23.05 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the total size of all Parquet files\n",
        "total_size_bytes = 0\n",
        "for file in parquet_files:\n",
        "    file_path = os.path.join(parquet_dir, file)\n",
        "    total_size_bytes += os.path.getsize(file_path)\n",
        "\n",
        "# Calculate the average size in MB\n",
        "average_size_MB = total_size_bytes / len(parquet_files) / (1024 * 1024)\n",
        "\n",
        "print(f\"Average size of the .parquet files: {average_size_MB} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyhOqgOR0bti",
        "outputId": "fca7ebfe-d13d-454d-f6df-94c2e2692341"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average size of the .parquet files: 23.042235136032104 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "\n",
        "Answer - 125,567\n",
        "\n",
        "\"We accidentally discovered that for Q3 homework 5 different versions of Spark give different answers\"\n",
        "\n",
        "How many taxi trips were there on the 15th of October?\n",
        "\n",
        "Consider only trips that started on the 15th of October."
      ],
      "metadata": {
        "id": "p8Z7WQN4-Pha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the schema of the DataFrame (structure of the columns)\n",
        "df.printSchema()\n",
        "\n",
        "# Get the column names (headers)\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6hERSpj-RpI",
        "outputId": "bd28fdd3-4276-48b1-89d6-997cc061a6c9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- VendorID: integer (nullable = true)\n",
            " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
            " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
            " |-- passenger_count: long (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- RatecodeID: long (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- PULocationID: integer (nullable = true)\n",
            " |-- DOLocationID: integer (nullable = true)\n",
            " |-- payment_type: long (nullable = true)\n",
            " |-- fare_amount: double (nullable = true)\n",
            " |-- extra: double (nullable = true)\n",
            " |-- mta_tax: double (nullable = true)\n",
            " |-- tip_amount: double (nullable = true)\n",
            " |-- tolls_amount: double (nullable = true)\n",
            " |-- improvement_surcharge: double (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            " |-- congestion_surcharge: double (nullable = true)\n",
            " |-- Airport_fee: double (nullable = true)\n",
            "\n",
            "['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'Airport_fee']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, to_timestamp\n",
        "\n",
        "# Convert the 'lpep_pickup_datetime' to timestamp if it is not already\n",
        "df = df.withColumn(\"lpep_pickup_datetime\", to_timestamp(\"tpep_pickup_datetime\", \"yyyy-MM-dd HH:mm:ss\"))\n",
        "\n",
        "# Filter the rows for trips on the 15th of October\n",
        "oct_15_trips = df.filter(col(\"lpep_pickup_datetime\").between(\"2024-10-15 00:00:00\", \"2024-10-15 23:59:59\"))\n",
        "\n",
        "# Count the number of trips on the 15th of October\n",
        "oct_15_count = oct_15_trips.count()\n",
        "\n",
        "print(f\"Number of taxi trips on the 15th of October: {oct_15_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYRg3zwj-t81",
        "outputId": "7a608d01-28b7-4aa5-9700-dfb4c4862bfe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of taxi trips on the 15th of October: 128893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "\n",
        "Answer - 162\n",
        "\n",
        "What is the length of the longest trip in the dataset in hours?\n"
      ],
      "metadata": {
        "id": "7TiFeif2_P63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, unix_timestamp\n",
        "\n",
        "# Calculate the duration in seconds\n",
        "df_with_duration = df.withColumn(\n",
        "    \"duration_seconds\",\n",
        "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\"))\n",
        ")\n",
        "\n",
        "# Convert the duration to hours\n",
        "df_with_duration = df_with_duration.withColumn(\"duration_hours\", col(\"duration_seconds\") / 3600)\n",
        "\n",
        "# Find the trip with the longest duration in hours\n",
        "longest_trip_in_hours = df_with_duration.orderBy(col(\"duration_hours\").desc()).first()\n",
        "\n",
        "# Print the details of the longest trip\n",
        "print(\"Longest trip details (in hours):\")\n",
        "print(longest_trip_in_hours)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWYDbzXK_Rgt",
        "outputId": "3177e8cb-e483-43e6-cbc8-a7678c3cb527"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest trip details (in hours):\n",
            "Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2024, 10, 16, 13, 3, 49), tpep_dropoff_datetime=datetime.datetime(2024, 10, 23, 7, 40, 53), passenger_count=1, trip_distance=32.37, RatecodeID=3, store_and_fwd_flag='N', PULocationID=48, DOLocationID=265, payment_type=2, fare_amount=152.5, extra=0.0, mta_tax=0.0, tip_amount=0.0, tolls_amount=17.38, improvement_surcharge=1.0, total_amount=170.88, congestion_surcharge=0.0, Airport_fee=0.0, lpep_pickup_datetime=datetime.datetime(2024, 10, 16, 13, 3, 49), duration_seconds=585424, duration_hours=162.61777777777777)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "\n",
        "Answer - 4040\n",
        "\n",
        "Spark’s User Interface which shows the application's dashboard runs on which local port?\n",
        "\n",
        "\n",
        "https://spark.apache.org/docs/3.5.4/cluster-overview.html"
      ],
      "metadata": {
        "id": "7pDnlwztAHTT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZzyfCwVAKAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "\n",
        "Answer -  Governor's Island/Ellis Island/Liberty Island\n",
        "\n"
      ],
      "metadata": {
        "id": "0Mtp3s1RAqad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzAPmNcA7Lx",
        "outputId": "77f198fc-1e9a-44c9-958a-e5e1d009c6c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-04 02:37:21--  https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\n",
            "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 52.85.39.65, 52.85.39.97, 52.85.39.153, ...\n",
            "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|52.85.39.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12331 (12K) [text/csv]\n",
            "Saving to: ‘taxi_zone_lookup.csv’\n",
            "\n",
            "taxi_zone_lookup.cs 100%[===================>]  12.04K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-04 02:37:21 (236 MB/s) - ‘taxi_zone_lookup.csv’ saved [12331/12331]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a Spark DataFrame\n",
        "zone_df = spark.read.csv('taxi_zone_lookup.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Show the first few rows to verify the data\n",
        "zone_df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QUMYkqyBEVl",
        "outputId": "4a386c1f-6f7f-43dd-eaf1-27c86a1e24b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+--------------------+------------+\n",
            "|LocationID|      Borough|                Zone|service_zone|\n",
            "+----------+-------------+--------------------+------------+\n",
            "|         1|          EWR|      Newark Airport|         EWR|\n",
            "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
            "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
            "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
            "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
            "+----------+-------------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary view\n",
        "zone_df.createOrReplaceTempView(\"zone_lookup\")\n",
        "\n",
        "# Verify by running a simple SQL query on the temporary view\n",
        "spark.sql(\"SELECT * FROM zone_lookup LIMIT 5\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm7NOb0JBGBR",
        "outputId": "1b304629-da12-4130-b4e4-af09d58d2510"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+--------------------+------------+\n",
            "|LocationID|      Borough|                Zone|service_zone|\n",
            "+----------+-------------+--------------------+------------+\n",
            "|         1|          EWR|      Newark Airport|         EWR|\n",
            "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
            "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
            "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
            "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
            "+----------+-------------+--------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"yellow_tripdata\")\n"
      ],
      "metadata": {
        "id": "wpbvBXSMBn09"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL query to find the least frequent pickup location zone\n",
        "query = \"\"\"\n",
        "    SELECT z.Zone, COUNT(*) as trip_count\n",
        "    FROM yellow_tripdata y\n",
        "    JOIN zone_lookup z\n",
        "    ON y.PULocationID = z.LocationID\n",
        "    GROUP BY z.Zone\n",
        "    ORDER BY trip_count ASC\n",
        "    LIMIT 1\n",
        "\"\"\"\n",
        "\n",
        "# Execute the SQL query\n",
        "least_frequent_zone = spark.sql(query)\n",
        "\n",
        "# Show the result\n",
        "least_frequent_zone.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wjxP_iqBvQT",
        "outputId": "5533d62f-c743-4dda-a1eb-22d6a21fbd19"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|                Zone|trip_count|\n",
            "+--------------------+----------+\n",
            "|Governor's Island...|         1|\n",
            "+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}